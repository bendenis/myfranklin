<!doctype html> <html lang=en > <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1"> <link rel=stylesheet  href="/myfranklin/libs/katex/katex.min.css"> <link rel=stylesheet  href="/myfranklin/libs/highlight/github.min.css"> <link rel=stylesheet  href="/myfranklin/css/franklin.css"> <link rel=stylesheet  href="/myfranklin/css/basic.css"> <link rel=icon  href="/myfranklin/assets/favicon.png"> <title>Building a NN with Julia from the ground up</title> <header> <div class=blog-name ><a href="/myfranklin/">Ben's Data Science</a></div> <nav> <ul> <li><a href="/myfranklin/">About</a> <li><a href="/myfranklin/blog_page/">Blog</a> <!---<li><a href="/myfranklin/menu2/">More goodies</a> ---> <!---<li><a href="/myfranklin/menu3/">Tags</a> ---> </ul> <img src="/myfranklin/assets/hamburger.svg" id=menu-icon > </nav> </header> <div class=franklin-content ><h1 id=building_a_nn_with_julia_from_the_ground_up ><a href="#building_a_nn_with_julia_from_the_ground_up" class=header-anchor >Building a NN with Julia from the ground up</a></h1> <pre><code class=language-julia >using Distributions
using RDatasets
using DataFrames
using Flux
using Plots
using Random

market_data &#61; dataset&#40;&quot;ISLR&quot;, &quot;Smarket&quot;&#41;
Y &#61; Int.&#40;transpose&#40;market_data.Direction .&#61;&#61; &quot;Up&quot;&#41;&#41;
X &#61; transpose&#40;Matrix&#40;select&#40;market_data, Not&#40;&#91;:Direction,:Today,:Year&#93;&#41;&#41;&#41;&#41;

@show &#40;first&#40;market_data,10&#41;&#41;
println&#40;&quot;&quot;&#41;
@show size&#40;X&#41;, size&#40;Y&#41;</code></pre> <pre><code class="plaintext code-output">ArgumentError: Package DataFrames not found in current path:
- Run `import Pkg; Pkg.add("DataFrames")` to install the DataFrames package.

</code></pre> <pre><code class=language-julia >plot&#40;market_data.Today&#41;</code></pre>
<pre><code class="plaintext code-output">UndefVarError: market_data not defined
</code></pre>
<div class=franklin-toc ><ol><li><a href="#forward_propagation">Forward Propagation</a><ol><li><a href="#connection_to_linear_regression">Connection to Linear Regression</a><li><a href="#multiple_layers_and_activation">Multiple Layers and Activation</a><li><a href="#initializing_parameters_weights_and_bias">Initializing Parameters &#40;Weights and Bias&#41;</a><li><a href="#forward_propagation_step">Forward Propagation Step</a><li><a href="#activation_step">Activation Step</a><li><a href="#combining_forward_activation_steps">Combining Forward &amp; Activation Steps</a><li><a href="#compute_fitted_values_forward_propagation">Compute Fitted Values &#40;Forward Propagation&#41;</a></ol><li><a href="#backward_propagation">Backward  Propagation</a><ol><li><a href="#computing_parameter_gradients">Computing Parameter Gradients</a><li><a href="#computing_layer_gradients">Computing Layer Gradients</a><li><a href="#computing_all_of_the_gradients">Computing All of the Gradients</a></ol><li><a href="#optimization">Optimization</a><ol><li><a href="#updating_parameters">Updating Parameters</a><li><a href="#cost_function">Cost Function</a><li><a href="#itterating">Itterating</a></ol></ol></div>
<h2 id=forward_propagation ><a href="#forward_propagation" class=header-anchor >Forward Propagation</a></h2>
<h3 id=connection_to_linear_regression ><a href="#connection_to_linear_regression" class=header-anchor >Connection to Linear Regression</a></h3>
<p>If you are familiar with linear regression the formulas for the forward propagation will look familiar. There are a couple things worth pointing out though. Just as a referrence here is the formula for the linear regression</p>
<span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>E</mi><mo stretchy=false >(</mo><mi>Y</mi><mo stretchy=false >)</mo><mo>=</mo><mn>1</mn><msub><mi>β</mi><mn>0</mn></msub><mo>+</mo><mi>X</mi><msub><mi>β</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex"> E(Y) = 1 β_0 + Xβ_1 </annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class=mclose >)</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class=mord >1</span><span class=mord ><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span><span class=mspace  style="margin-right:0.2222222222222222em;"></span><span class=mbin >+</span><span class=mspace  style="margin-right:0.2222222222222222em;"></span></span><span class=base ><span class=strut  style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class=mord ><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>
<p>Here <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span> is the <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy=false >(</mo><mi>n</mi><mo separator=true >,</mo><mi>m</mi><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">(n,m)</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class=mopen >(</span><span class="mord mathnormal">n</span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">m</span><span class=mclose >)</span></span></span></span> data where each row is an observation and each column is a covariate/feature. So we have <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">n</span></span></span></span> observations and <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi></mrow><annotation encoding="application/x-tex">m</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">m</span></span></span></span> variables. Consequently <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>β</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">β_1</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> is an <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy=false >(</mo><mi>m</mi><mo separator=true >,</mo><mn>1</mn><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">(m,1)</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class=mopen >(</span><span class="mord mathnormal">m</span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class=mord >1</span><span class=mclose >)</span></span></span></span> vector of parameters. <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>β</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">β_0</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> is a scalar and the <em>1</em> is an <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy=false >(</mo><mi>n</mi><mo separator=true >,</mo><mn>1</mn><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">(n,1)</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class=mopen >(</span><span class="mord mathnormal">n</span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class=mord >1</span><span class=mclose >)</span></span></span></span> column vector of 1s.</p>
<p>A regression model like the one above can be represented as a single layer Neural Network model with one neuron. The notation is just a little bit different.</p>
<span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Z</mi><mo>=</mo><mi>W</mi><mi>A</mi><mo>+</mo><mi>b</mi></mrow><annotation encoding="application/x-tex"> Z = WA + b </annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mord mathnormal">A</span><span class=mspace  style="margin-right:0.2222222222222222em;"></span><span class=mbin >+</span><span class=mspace  style="margin-right:0.2222222222222222em;"></span></span><span class=base ><span class=strut  style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">b</span></span></span></span>
<p><span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal">A</span></span></span></span> is now an <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy=false >(</mo><mi>m</mi><mo separator=true >,</mo><mi>n</mi><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">(m,n)</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class=mopen >(</span><span class="mord mathnormal">m</span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">n</span><span class=mclose >)</span></span></span></span> matrix of data with one observation per <em>column</em> and one feature per <em>row</em>. Consequently <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>W</mi></mrow><annotation encoding="application/x-tex">W</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span></span></span></span> is an <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy=false >(</mo><mn>1</mn><mo separator=true >,</mo><mi>m</mi><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">(1,m)</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class=mopen >(</span><span class=mord >1</span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">m</span><span class=mclose >)</span></span></span></span> vector of weights &#40;just like <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>β</mi><mn>1</mn><mi>T</mi></msubsup></mrow><annotation encoding="application/x-tex">β^T_1</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1.0894389999999998em;vertical-align:-0.24810799999999997em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.8413309999999999em;"><span style="top:-2.4518920000000004em;margin-left:-0.05278em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.24810799999999997em;"><span></span></span></span></span></span></span></span></span></span>&#41;. <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">b</span></span></span></span> is the same scalar as <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>β</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">β_0</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> but the <em>1</em> is a <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy=false >(</mo><mn>1</mn><mo separator=true >,</mo><mi>n</mi><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">(1,n)</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class=mopen >(</span><span class=mord >1</span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">n</span><span class=mclose >)</span></span></span></span> row vector. </p>
<p>Essentially when computing NNs we transpose everything. Coming from a statistics background this can be a bit uncomfortable at first but with time you get use to it.</p>
<h3 id=multiple_layers_and_activation ><a href="#multiple_layers_and_activation" class=header-anchor >Multiple Layers and Activation</a></h3>
<p>But of course the point of Neural Networks is that you can increase the coplexity of the model with many layers and many neurons per layer. And of course we introduce non-linearity by transforming the output of each layer. This transformation is called an <em>activation</em>. </p>
<p>For example if we wish to have <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span> neurons in out layer we would set <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>W</mi></mrow><annotation encoding="application/x-tex">W</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span></span></span></span> to be <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy=false >(</mo><mi>k</mi><mo separator=true >,</mo><mi>m</mi><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">(k,m)</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">m</span><span class=mclose >)</span></span></span></span>. The output <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Z</mi></mrow><annotation encoding="application/x-tex">Z</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span></span></span></span> will then become a <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy=false >(</mo><mi>k</mi><mo separator=true >,</mo><mi>n</mi><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">(k,n)</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">n</span><span class=mclose >)</span></span></span></span> matrix as aposed to a <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy=false >(</mo><mn>1</mn><mo separator=true >,</mo><mi>n</mi><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">(1,n)</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class=mopen >(</span><span class=mord >1</span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">n</span><span class=mclose >)</span></span></span></span> in a linear regression model. </p>
<p>Next we activate <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Z</mi></mrow><annotation encoding="application/x-tex">Z</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span></span></span></span> by applying an activation function and get a <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy=false >(</mo><mi>k</mi><mo separator=true >,</mo><mi>n</mi><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">(k,n)</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">n</span><span class=mclose >)</span></span></span></span>, <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mo>=</mo><mi>g</mi><mo stretchy=false >(</mo><mi>Z</mi><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">A = g(Z)</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal">A</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span><span class=mclose >)</span></span></span></span>. If we stop with one layer then this is the final output. But we won&#39;t. </p>
<p>To add another layer with <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>j</mi></mrow><annotation encoding="application/x-tex">j</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.85396em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span></span></span></span> units we introduce another <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy=false >(</mo><mi>j</mi><mo separator=true >,</mo><mi>k</mi><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">(j,k)</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class=mclose >)</span></span></span></span> matrix <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>W</mi><mn>2</mn></mrow><annotation encoding="application/x-tex">W2</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class=mord >2</span></span></span></span> and <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi><mn>2</mn></mrow><annotation encoding="application/x-tex">b2</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">b</span><span class=mord >2</span></span></span></span>. And so on..</p>
<p>With multiple layers the general equations for forward propagation are:</p>
<ol>
<li><p><span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Z</mi><mi>l</mi></msub><mo>=</mo><msubsup><mi>W</mi><mi>l</mi><mi>T</mi></msubsup><msub><mi>A</mi><mrow><mi>l</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>+</mo><msub><mi>b</mi><mi>l</mi></msub></mrow><annotation encoding="application/x-tex"> Z_{l} = W_{l}^T A_{l-1} + b_{l} </annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.83333em;vertical-align:-0.15em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:1.1244389999999997em;vertical-align:-0.2831079999999999em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.8413309999999999em;"><span style="top:-2.4168920000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.2831079999999999em;"><span></span></span></span></span></span></span><span class=mord ><span class="mord mathnormal">A</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.208331em;"><span></span></span></span></span></span></span><span class=mspace  style="margin-right:0.2222222222222222em;"></span><span class=mbin >+</span><span class=mspace  style="margin-right:0.2222222222222222em;"></span></span><span class=base ><span class=strut  style="height:0.84444em;vertical-align:-0.15em;"></span><span class=mord ><span class="mord mathnormal">b</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></p>

<li><p><span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>A</mi><mi>l</mi></msub><mo>=</mo><msub><mi>g</mi><mi>l</mi></msub><mo stretchy=false >(</mo><msub><mi>Z</mi><mi>l</mi></msub><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex"> A_{l} = g_l(Z_l) </annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.83333em;vertical-align:-0.15em;"></span><span class=mord ><span class="mord mathnormal">A</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span><span class=mopen >(</span><span class=mord ><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span><span class=mclose >)</span></span></span></span></p>

</ol>
<p>where l goes from <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mi>t</mi><mi>o</mi><mi>L</mi></mrow><annotation encoding="application/x-tex">1 to L</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.68333em;vertical-align:0em;"></span><span class=mord >1</span><span class="mord mathnormal">t</span><span class="mord mathnormal">o</span><span class="mord mathnormal">L</span></span></span></span> and L is the number of layers.</p>
<h3 id=initializing_parameters_weights_and_bias ><a href="#initializing_parameters_weights_and_bias" class=header-anchor >Initializing Parameters &#40;Weights and Bias&#41;</a></h3>
<p>Step 0 is to randomly initialize all of the parameter matrices <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>W</mi><mi>l</mi></msub></mrow><annotation encoding="application/x-tex">W_l</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.83333em;vertical-align:-0.15em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> and vecotrs <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>b</mi><mi>l</mi></msub></mrow><annotation encoding="application/x-tex">b_l</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.84444em;vertical-align:-0.15em;"></span><span class=mord ><span class="mord mathnormal">b</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>. This is where keeping track of the dimentions becomes extremly important. <code>initialize_parameters_deep</code> is the function that does this given an array of integers. The length of the array is the number of layers L and the integers are the number of neurons per layer.</p>
<pre><code class=language-julia >function initialize_parameters_deep&#40;layer_dims&#41;
    parameters &#61; Dict&#40;&#41;

    for l in 1:&#40;length&#40;layer_dims&#41; - 1&#41;
        parameters&#91;&quot;W&quot; * string&#40;l&#41;&#93; &#61; rand&#40;layer_dims&#91;l&#43;1&#93;, layer_dims&#91;l&#93;&#41; .* 0.01
        parameters&#91;&quot;b&quot; * string&#40;l&#41;&#93; &#61; rand&#40;layer_dims&#91;l&#43;1&#93;, 1&#41; .* 0.01
    end

    return&#40;parameters&#41;
end</code></pre>
<pre><code class=language-julia >number_of_input_features &#61; size&#40;X&#41;&#91;1&#93;
model_form &#61; &#91;number_of_input_features,8,4,2,1&#93;

init_parameters &#61; initialize_parameters_deep&#40;model_form&#41;

&#91;
    println&#40;&quot;Parameters: &quot; * k * &quot; of size &quot; * string&#40;size&#40;init_parameters&#91;k&#93;&#41;&#41;&#41; 
    for k in keys&#40;init_parameters&#41;
&#93;</code></pre>
<pre><code class="plaintext code-output">UndefVarError: X not defined
</code></pre>
<h3 id=forward_propagation_step ><a href="#forward_propagation_step" class=header-anchor >Forward Propagation Step</a></h3>
<pre><code class=language-julia >function linear_forward&#40;A, W, b&#41;
    Z &#61; W * A .&#43; b
    cache &#61; &#40;A &#61; A, W &#61; W, b &#61; b&#41;
    return&#40;&#40;Z &#61; Z, cache &#61; cache&#41;&#41;
end</code></pre>
<pre><code class=language-julia >A &#61; X
W &#61; init_parameters&#91;&quot;W1&quot;&#93;
b &#61; init_parameters&#91;&quot;b1&quot;&#93;
Z, cache &#61; linear_forward&#40;A, W, b&#41;

@show DataFrame&#40;Z, :auto&#41;</code></pre>
<pre><code class="plaintext code-output">UndefVarError: X not defined
</code></pre>
<h3 id=activation_step ><a href="#activation_step" class=header-anchor >Activation Step</a></h3>
<pre><code class=language-julia >function sigmoid&#40;Z&#41;
    A &#61; 1 ./ &#40;1 .&#43; exp.&#40;-Z&#41;&#41;
    return&#40;&#40;A &#61; A, Z &#61; Z&#41;&#41;
end

function relu&#40;Z&#41;
    A &#61; copy&#40;Z&#41;
    A&#91;A .&lt; 0&#93; .&#61; 0
    return&#40;&#40;A &#61; A, Z &#61; Z&#41;&#41;
end</code></pre>
<pre><code class=language-julia >next_A, cache_Z &#61; relu&#40;Z&#41;
@show DataFrame&#40;next_A, :auto&#41;</code></pre>
<pre><code class="plaintext code-output">UndefVarError: Z not defined
</code></pre>
<h3 id=combining_forward_activation_steps ><a href="#combining_forward_activation_steps" class=header-anchor >Combining Forward &amp; Activation Steps</a></h3>
<pre><code class=language-julia >function linear_activation_forward&#40;Aprev, W, b, activation&#41;
    if activation &#61;&#61; &quot;sigmoid&quot;
        Z, linear_cache &#61; linear_forward&#40;Aprev, W, b&#41;
        A, activation_cache &#61; sigmoid&#40;Z&#41;
    elseif  activation &#61;&#61; &quot;relu&quot;
        Z, linear_cache &#61; linear_forward&#40;Aprev, W, b&#41;
        A, activation_cache &#61; relu&#40;Z&#41;
    end
    
    cache &#61; &#40;linear_cache, activation_cache&#41;

    return&#40;&#40;A &#61; A, cache &#61; cache&#41;&#41;
end</code></pre>
<pre><code class=language-julia >A &#61; X
W &#61; init_parameters&#91;&quot;W1&quot;&#93;
b &#61; init_parameters&#91;&quot;b1&quot;&#93;
A, cache &#61; linear_activation_forward&#40;A, W, b, &quot;relu&quot;&#41;

@show DataFrame&#40;A, :auto&#41;</code></pre>
<pre><code class="plaintext code-output">UndefVarError: X not defined
</code></pre>
<h3 id=compute_fitted_values_forward_propagation ><a href="#compute_fitted_values_forward_propagation" class=header-anchor >Compute Fitted Values &#40;Forward Propagation&#41;</a></h3>
<pre><code class=language-julia >function L_model_forward&#40;X, parameters&#41;
    A &#61; copy&#40;X&#41;
    L &#61; Int&#40;length&#40;parameters&#41; / 2&#41;
    caches &#61; &#91;&#93;

    for l in 1:&#40;L-1&#41;
        Aprev &#61; copy&#40;A&#41;
        A, cache &#61; linear_activation_forward&#40;Aprev, 
                    parameters&#91;&quot;W&quot;*string&#40;l&#41;&#93;, 
                    parameters&#91;&quot;b&quot;*string&#40;l&#41;&#93;,
                    &quot;relu&quot;&#41;
        push&#33;&#40;caches, cache&#41;
    end

    AP, cache &#61; linear_activation_forward&#40;A, 
                parameters&#91;&quot;W&quot;*string&#40;L&#41;&#93;, 
                parameters&#91;&quot;b&quot;*string&#40;L&#41;&#93;,
                &quot;sigmoid&quot;&#41;
    push&#33;&#40;caches, cache&#41;

    return AP, caches
end</code></pre>
<pre><code class=language-julia >Ŷ, caches &#61; L_model_forward&#40;X, init_parameters&#41;
@show Ŷ</code></pre>
<pre><code class="plaintext code-output">UndefVarError: X not defined
</code></pre>
<p>Accuracy with no training, just the dafult random parameters</p>
<pre><code class=language-julia >predictions &#61; Ŷ .&gt; 0.5
acc &#61; mean&#40;Y .&#61;&#61; predictions&#41;
@show  acc</code></pre>
<pre><code class="plaintext code-output">UndefVarError: Ŷ not defined
</code></pre>
<h2 id=backward_propagation ><a href="#backward_propagation" class=header-anchor >Backward  Propagation</a></h2>
<h3 id=computing_parameter_gradients ><a href="#computing_parameter_gradients" class=header-anchor >Computing Parameter Gradients</a></h3>
<pre><code class=language-julia ># computing the W and b gradients 
function linear_backward&#40;∇Z, linear_cache&#41;
    Ap, Wl, bl &#61; linear_cache
    m &#61; size&#40;Ap&#41;&#91;2&#93;

    ∇Wl &#61; ∇Z*transpose&#40;Ap&#41; .* 1/m
    ∇bl &#61; mean&#40;∇Z, dims &#61; 2&#41;
    ∇Ap &#61; transpose&#40;Wl&#41;*∇Z

    return&#40;∇Ap, ∇Wl, ∇bl&#41;
end</code></pre>
<pre><code class=language-julia ># Functions to compute dZ given dA and Z &#40;from forward prop cache&#41;
function sigmoid_backward&#40;∇A, activation_cache&#41;
    Zl &#61; activation_cache
    Z &#61; σ.&#40;Zl&#41;.*&#40;1 .- σ.&#40;Zl&#41;&#41;
    ∇Z &#61; ∇A .* Z
    return&#40;∇Z&#41;
end

function relu_backward&#40;∇A, activation_cache&#41;
    Zl &#61; activation_cache
    Z &#61; copy&#40;Zl&#41;
    Z&#91;Zl .&gt; 0&#93; .&#61; 1
    Z&#91;Zl .&lt;&#61; 0&#93; .&#61; 0

    ∇Z &#61; ∇A .* Z

    return&#40;∇Z&#41;
end</code></pre>
<h3 id=computing_layer_gradients ><a href="#computing_layer_gradients" class=header-anchor >Computing Layer Gradients</a></h3>
<pre><code class=language-julia >function linear_activation_backward&#40;∇A, cache, activation&#41;
    linear_cache, activation_cache &#61; cache
    if activation &#61;&#61; &quot;sigmoid&quot;
        ∇Z &#61;  sigmoid_backward&#40;∇A, activation_cache&#41; 
        ∇Ap, ∇W, ∇b &#61;  linear_backward&#40;∇Z, linear_cache&#41;
    elseif activation &#61;&#61; &quot;relu&quot;
        ∇Z &#61;  relu_backward&#40;∇A, activation_cache&#41;
        ∇Ap, ∇W, ∇b &#61;  linear_backward&#40;∇Z, linear_cache&#41;
    end
    return&#40;∇Ap, ∇W, ∇b&#41;
end</code></pre>
<h3 id=computing_all_of_the_gradients ><a href="#computing_all_of_the_gradients" class=header-anchor >Computing All of the Gradients</a></h3>
<pre><code class=language-julia >function L_model_backward&#40;AP, Y, caches&#41;
    grads &#61; Dict&#40;&#41;
    L &#61; length&#40;caches&#41;

    # derivative of the Loss Function &#40;Cost&#41; w.r.t AP
    dAP &#61; -&#40;&#40;Y ./ AP&#41; .- &#40;&#40;1 .-Y&#41;./&#40;1 .- AP&#41;&#41;&#41;
    current_cache &#61; caches&#91;L&#93;

    dA_prev_temp, dW_temp, db_temp &#61; linear_activation_backward&#40;dAP, current_cache, &quot;sigmoid&quot;&#41;
    grads&#91;&quot;dA&quot; * string&#40;L-1&#41;&#93; &#61; dA_prev_temp
    grads&#91;&quot;dW&quot; * string&#40;L&#41;&#93; &#61; dW_temp
    grads&#91;&quot;db&quot; * string&#40;L&#41;&#93; &#61; db_temp

    for l in &#40;L-1&#41;:-1:1
        current_cache &#61; caches&#91;l&#93;
        dA_prev_temp, dW_temp, db_temp &#61; linear_activation_backward&#40;grads&#91;&quot;dA&quot; * string&#40;l&#41;&#93;, 
                                                current_cache, 
                                                &quot;relu&quot;&#41;

        grads&#91;&quot;dA&quot; * string&#40;l-1&#41;&#93; &#61; dA_prev_temp
        grads&#91;&quot;dW&quot; * string&#40;l&#41;&#93; &#61; dW_temp
        grads&#91;&quot;db&quot; * string&#40;l&#41;&#93; &#61; db_temp
    end

    return&#40;grads&#41;
end</code></pre>
<h2 id=optimization ><a href="#optimization" class=header-anchor >Optimization</a></h2>

<h3 id=updating_parameters ><a href="#updating_parameters" class=header-anchor >Updating Parameters</a></h3>
<pre><code class=language-julia >function update_parameters&#40;parameters, grads, learning_rate&#41;
    updated_parameters &#61; copy&#40;parameters&#41;
    L &#61; Int&#40;length&#40;updated_parameters&#41; / 2&#41;
    for l in 1:L
        updated_parameters&#91;&quot;W&quot; * string&#40;l&#41;&#93; &#61; updated_parameters&#91;&quot;W&quot; * string&#40;l&#41;&#93; .- learning_rate*grads&#91;&quot;dW&quot; * string&#40;l&#41;&#93;
        updated_parameters&#91;&quot;b&quot; * string&#40;l&#41;&#93; &#61; updated_parameters&#91;&quot;b&quot; * string&#40;l&#41;&#93; .- learning_rate*grads&#91;&quot;db&quot; * string&#40;l&#41;&#93;
    end
    return&#40;updated_parameters&#41;
end</code></pre>
<h3 id=cost_function ><a href="#cost_function" class=header-anchor >Cost Function</a></h3>
<pre><code class=language-julia >function compute_cost&#40;AP, Y&#41;
    cost &#61; -mean&#40;log.&#40;AP&#41; .* Y &#43; log.&#40;1 .- AP&#41; .* &#40;1 .- Y&#41;&#41;
    return cost
end</code></pre>
<h3 id=itterating ><a href="#itterating" class=header-anchor >Itterating</a></h3>
<pre><code class=language-julia >function pred_nn_model&#40;parameters, X&#41;
    Ŷ, cache &#61; L_model_forward&#40;X, parameters&#41;
    predictions &#61; Ŷ .&gt; 0.5

    return&#40;predictions&#41;
end</code></pre>
<pre><code class=language-julia >Random.seed&#33;&#40;007&#41;
params &#61; &#91;initialize_parameters_deep&#40;&#91;size&#40;X&#41;&#91;1&#93;,5,5,1&#93;&#41;&#93;

for i in 1:1000000
    AP, caches &#61; L_model_forward&#40;X, params&#91;i&#93;&#41;
    grads &#61; L_model_backward&#40;AP, Y, caches&#41;
    up &#61; update_parameters&#40;params&#91;i&#93;, grads, 0.1&#41;
    push&#33;&#40;params, up&#41;
    if i &#37; 100000 &#61;&#61; 0
        println&#40;compute_cost&#40;AP, Y&#41;&#41;
    end
end

acc &#61; mean&#40;Y .&#61;&#61; pred_nn_model&#40;params&#91;end&#93;, X&#41;&#41;

@show params&#91;begin&#93;
@show params&#91;end&#93;
@show acc</code></pre>
<pre><code class="plaintext code-output">UndefVarError: Random not defined
</code></pre>
<div class=page-foot >
  <div class=copyright >
    &copy; Ben Denis Shaffer. Last modified: October 24, 2021. Website built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a> and the <a href="https://julialang.org">Julia programming language</a>.
  </div>
</div>
</div>
    
        



    
    
        <script src="/myfranklin/libs/highlight/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();hljs.configure({tabReplace: '    '});</script>